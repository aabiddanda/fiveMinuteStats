<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Matthew Stephens" />

<meta name="date" content="2016-01-23" />

<title>Introduction to Gibbs Sampling</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>

<style type="text/css">

/* padding for bootstrap navbar */
body {
  padding-top: 50px;
  padding-bottom: 40px;
}


/* offset scroll position for anchor links (for fixed navbar)  */
.section h2 {
  padding-top: 55px;
  margin-top: -55px;
}
.section h3 {
  padding-top: 55px;
  margin-top: -55px;
}



/* don't use link color in navbar */
.dropdown-menu>li>a {
  color: black;
}

/* some padding for disqus */
#disqus_thread {
  margin-top: 45px;
}

</style>

<link rel="stylesheet" href="libs/font-awesome-4.1.0/css/font-awesome.min.css"/>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="libs/highlight/textmate.css"
      type="text/css" />
<script src="libs/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>




</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<div class="container-fluid main-container">

<!-- tabsets -->
<script src="libs/navigation-1.0/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">fiveMinuteStats</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li><a href="index.html">Home</a></li>
        <li><a href="about.html">About</a></li>
        <li><a href="license.html">License</a></li>
        <li><a href="https://github.com/stephens999/fiveMinuteStats">GitHub</a></li>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">


<h1 class="title">Introduction to Gibbs Sampling</h1>
<h4 class="author"><em>Matthew Stephens</em></h4>
<h4 class="date"><em>2016-01-23</em></h4>

</div>

<div id="TOC">
<ul>
<li><a href="#pre-requisites">Pre-requisites</a></li>
<li><a href="#overview">Overview</a></li>
<li><a href="#gibbs-sampling">Gibbs Sampling</a></li>
<li><a href="#explanation">Explanation</a><ul>
<li><a href="#session-information">Session information</a></li>
</ul></li>
</ul>
</div>

<p><strong>Last updated:</strong> 2016-05-02</p>
<p><strong>Code version:</strong> 47f75caf1de71c54b1973a2c2439b7b851b7e737</p>
<div id="pre-requisites" class="section level1">
<h1>Pre-requisites</h1>
<p>Be familiar with the concept of joint distribution and a conditional distribution. Ideally also with the concept of a Markov chain and its stationary distribution.</p>
</div>
<div id="overview" class="section level1">
<h1>Overview</h1>
<p>Gibbs sampling is a very useful way of simulating from distributions that are difficult to simulate from directly. However, in this introduction to the key concept, we will use a Gibbs sampler to simulate from a very simple distribution that could be simulated from in other ways.</p>
</div>
<div id="gibbs-sampling" class="section level1">
<h1>Gibbs Sampling</h1>
<p>Suppose <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are two binary random variables with joint distribution <span class="math inline">\(\Pr(X=x,Y=y) = p_{X,Y}(x,y)\)</span> given by the following table:</p>
<table>
<thead>
<tr class="header">
<th align="left">X \ Y</th>
<th align="left">0</th>
<th align="left">1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">0</td>
<td align="left">0.6</td>
<td align="left">0.1</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">0.15</td>
<td align="left">0.15</td>
</tr>
</tbody>
</table>
<p>That is, for example, <span class="math inline">\(p_{X,Y}(0,0)=0.6\)</span>.</p>
<p>The conditional distribution of <span class="math inline">\(X\)</span> given any given value is easy to compute by the usual formula for conditional probability, <span class="math inline">\(\Pr(A | B) = \Pr(A and B)/\Pr(B)\)</span>. For example: <span class="math display">\[\Pr(X=0 | Y=0) = \Pr(X=0 \cap Y=0)/Pr(Y=0) = 0.6/0.75 = 0.8\]</span> and so <span class="math display">\[\Pr(X=1 | Y=0) = 1-0.8 = 0.2.\]</span> Similarly <span class="math display">\[\Pr(X=0 | Y=1) = 0.1/0.25 = 0.4\]</span> and so <span class="math display">\[\Pr(X=1 | Y=1) = 0.6\]</span>.</p>
<p>We can just as easily compute the conditional distribution of <span class="math inline">\(Y\)</span> for any given value of <span class="math inline">\(X\)</span>: <span class="math display">\[\Pr(Y=0 | X=0) = 6/7\]</span> <span class="math display">\[\Pr(Y=1 | X=0) = 1/7\]</span> <span class="math display">\[\Pr(Y=0 | X=1) = 1/2\]</span> <span class="math display">\[\Pr(Y=1 | X=1) = 1/2\]</span></p>
<p>Now the question: what if we start at some value of <span class="math inline">\(X,Y\)</span> and proceed to iterate the following steps: 1. Simulate a new value of <span class="math inline">\(X\)</span> from <span class="math inline">\(\Pr(X | Y=y)\)</span> where <span class="math inline">\(y\)</span> is the current value of <span class="math inline">\(Y\)</span>. 2. Simulate a new value of <span class="math inline">\(Y\)</span> from <span class="math inline">\(\Pr(Y | X=x)\)</span> where <span class="math inline">\(x\)</span> is the current value of <span class="math inline">\(X\)</span> (generated in 1.) What happens?</p>
<p>Let’s try it:</p>
<pre class="r"><code>#returns 1 with probability p, and 0 with probability 1-p
rbernoulli=function(p){return(1*runif(1)&lt;p)}

# sample from distribution X given Y above
sample_XgivenY = function(y){
 if(y==0){
   x = rbernoulli(0.2) # returns 1 with probability 0.2; otherwise 0
 } else {
   x = rbernoulli(0.6)
 } 
  return(x)
}
#&#39; sample from distribution Y given X above
sample_YgivenX = function(x){
  if(x==0){
    y = rbernoulli(1/7)
  } else {
    y = rbernoulli(0.5)
  }
  return(y)
}
set.seed(100)
niter = 1000
X = rep(0,niter)
Y = rep(0,niter)
X[1]=1
Y[1]=1 # start from (1,1)
for(i in 2:niter){
  X[i] = sample_XgivenY(Y[i-1])
  Y[i] = sample_YgivenX(X[i])
}
res = data.frame(X=X,Y=Y)</code></pre>
<p>Here is what happens for the first 20 iterations:</p>
<pre class="r"><code>head(res,20)</code></pre>
<pre><code>   X Y
1  1 1
2  1 1
3  1 1
4  1 1
5  0 0
6  0 0
7  0 0
8  0 0
9  0 0
10 0 0
11 0 0
12 0 0
13 0 0
14 0 0
15 0 0
16 0 0
17 0 0
18 0 0
19 0 0
20 1 0</code></pre>
<p>And here is a summary of what proportion of the rows are of each type:</p>
<pre class="r"><code>table(data.frame(X=X,Y=Y))/niter</code></pre>
<pre><code>   Y
X       0     1
  0 0.617 0.092
  1 0.154 0.137</code></pre>
<p>As you can see, the proportion of iterations in which <span class="math inline">\(X=x\)</span> and <span class="math inline">\(Y=y\)</span> is very close to <span class="math inline">\(\Pr(X=x,Y=y)=p_{X,Y}(x,y)\)</span>. This is not a coincidence!</p>
</div>
<div id="explanation" class="section level1">
<h1>Explanation</h1>
<p>What we have done here is simulate a Markov chain <span class="math display">\[(X_1,Y_1), (X_2,Y_2), (X_3,Y_3), \dots\]</span>, whose stationary distribution is <span class="math inline">\(\Pr(X=x,Y=y)=p_{X,Y}(x,y)\)</span>.</p>
<p>To see that the pairs <span class="math inline">\((X,Y)\)</span> form a Markov chain, note that the simulation of <span class="math inline">\(X_i\)</span> is done using only the previous value <span class="math inline">\(Y_{i-1}\)</span>, and the simulation of <span class="math inline">\(Y_i\)</span> is done using only <span class="math inline">\(X_i\)</span>. So simulation of <span class="math inline">\((X_i,Y_i)\)</span> depends on the previous states only through the immediate previous state <span class="math inline">\((X_{i-1},Y_{i-1})\)</span>, which means it is a Markov chain. (And in fact it only depends on <span class="math inline">\(Y_{i-1}\)</span>, but that is not so important.)</p>
<p>To see why it has stationary distribution <span class="math inline">\(p_{X,Y}(x,y)\)</span> imagine simulating <span class="math inline">\(X_1,Y_1\)</span> from this distribution, so <span class="math inline">\(\Pr(X_1=x,Y_1=y)= p_{X,Y}(x,y)\)</span>, and in particular <span class="math inline">\(\Pr(Y_1=y)= \sum_x p_{X,Y}(x,y) = p_Y(y)\)</span>.</p>
<p>Now, what is <span class="math inline">\(\Pr(X_2=x,Y_1=y)\)</span>? Well we know <span class="math display">\[\Pr(X_2=x,Y_1=y) = \Pr(Y_1=y) \Pr(X_2=x| Y_1=y).\]</span> And we know from above that <span class="math display">\[\Pr(Y_1=y) = p_{Y}(y).\]</span> And we know that given <span class="math inline">\(Y_1-y\)</span>, <span class="math inline">\(X_2\)</span> was simulated from the conditional distribution <span class="math inline">\(p_{X|Y}(x|y)\)</span>, so <span class="math display">\[\Pr(X_2=x | Y_1=y) = p_{X|Y}(x|y).\]</span> Putting these together we have <span class="math display">\[\Pr(X_2=x,Y_1=y) = p_{Y}(y)p_{X|Y}(x|y) = p_{X,Y}(x,y).\]</span></p>
<p>Now, essentially the same argument shows that <span class="math inline">\(\Pr(X_2=x, Y_2=y) = p_{X,Y}(x,y)\)</span>. [Exercise]</p>
<p>Thus, we have shown that <em>if</em> <span class="math inline">\(\Pr(X_1=x, Y_1=y) = p_{X,Y}(x,y)\)</span> then also <span class="math inline">\(\Pr(X_2=x, Y_2=y) = p_{X,Y}(x,y)\)</span>. That is exactly what it means for <span class="math inline">\(p_{X,Y}(x,y)\)</span> to be the stationary distribution: if we start the chain by simulating from that distribution then it remains in that distribution after one step, and so it remains in that distribution for ever.</p>
<p>Of course, we did <em>not</em> start the chain at that distribution. But the above argument shows that this is indeed the stationary distribution. There is a general result that discrete Markov chains converge to their stationary distribution, provided that they are what is called “irreducible and aperiodic” (which this Markov chain is). That is, for large enough <span class="math inline">\(n\)</span>, we should see <span class="math inline">\(\Pr(X_n=x, Y_n=y) \approx p_{X,Y}(x,y)\)</span> no matter where we start. Furthermore, in the long-run, the proportion of iterations spent in each state will also converge to this distribution.</p>
<p>This explains the simulation result.</p>
<div id="session-information" class="section level2">
<h2>Session information</h2>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 3.2.4 (2016-03-10)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.11.3 (El Capitan)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] knitr_1.12.3

loaded via a namespace (and not attached):
 [1] magrittr_1.5    formatR_1.3     tools_3.2.4     htmltools_0.3.5
 [5] yaml_2.1.13     Rcpp_0.12.4     stringi_1.0-1   rmarkdown_0.9.5
 [9] stringr_1.0.0   digest_0.6.9    evaluate_0.8.3 </code></pre>
</div>
</div>


<!-- some extra javascript for older browsers -->
<script type="text/javascript" src="libs/polyfill.js"></script>

<script>

// manage active state of menu based on current page
$(document).ready(function () {

    // active menu
    href = window.location.pathname
    href = href.substr(href.lastIndexOf('/') + 1)
    $('a[href="' + href + '"]').parent().addClass('active');

    // manage active menu header
    if (href.startsWith('authoring_'))
      $('a[href="' + 'authoring' + '"]').parent().addClass('active');
    else if (href.endsWith('_format.html'))
      $('a[href="' + 'formats' + '"]').parent().addClass('active');
    else if (href.startsWith('developer_'))
      $('a[href="' + 'developer' + '"]').parent().addClass('active');

});

</script>



</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
